{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPqS8vDWfdiY"
      },
      "outputs": [],
      "source": [
        "#all important stuff to make sure code runs well\n",
        "from sklearn import svm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import random\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data set\n",
        "data = pd.read_csv('cardio_train.csv', sep = ';')"
      ],
      "metadata": {
        "id": "KNdg1tA_fnTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for null values\n",
        "null_rows = data[data.isnull().any(axis=1)].head()\n",
        "#print(null_rows.head()) #-->no null values\n",
        "\n",
        "#check whether data set is balanced\n",
        "sick = data['cardio'].value_counts()[1]\n",
        "healthy = len(data) - data['cardio'].value_counts()[1]\n",
        "#print(\"sick: \", sick, \"individuals; healthy: \", healthy, \"individuals\")\n",
        "\n",
        "data_target = data['cardio']\n",
        "data['BMI'] = data['weight'] / (data['height'] / 100)**2\n",
        "#convert age to years so we can interpret it better\n",
        "data['age'] = data['age'] / 365\n",
        "#check correlations of features to target value\n",
        "numerdata = data.drop(columns=['gender', 'cholesterol', 'gluc',\t'smoke',\t'alco','active','BMI'])\n",
        "print(numerdata.corr()['cardio'].sort_values(ascending=False))\n",
        "\n",
        "#dropping the label column & id feature\n",
        "data = data.drop(columns=['cardio', 'id','height'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEterZuFfqEh",
        "outputId": "579490ca-6c03-4969-e8be-5208c2b16b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardio    1.000000\n",
            "age       0.238159\n",
            "weight    0.181660\n",
            "ap_lo     0.065719\n",
            "ap_hi     0.054475\n",
            "id        0.003799\n",
            "height   -0.010821\n",
            "Name: cardio, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one-hot encoding the categorical features & normalizing the numerical features\n",
        "numerical_features = ['age', 'weight', 'ap_hi', 'ap_lo']\n",
        "categorical_features = ['gender', 'cholesterol', 'gluc',\t'smoke',\t'alco','active']\n",
        "full_pipeline = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), numerical_features),\n",
        "     (\"cat\", OneHotEncoder(), categorical_features)\n",
        "    ])\n",
        "\n",
        "data = full_pipeline.fit_transform(data)\n",
        "categorical_feature_names = full_pipeline.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
        "\n",
        "# Combine numerical and categorical feature names\n",
        "all_feature_names = numerical_features + list(categorical_feature_names)\n",
        "\n",
        "# Create the DataFrame\n",
        "transformed_df = pd.DataFrame(data, columns=all_feature_names)\n",
        "\n",
        "data = transformed_df\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu-JTg5FfwRY",
        "outputId": "e4274a9c-9a2c-4972-f37f-4656af78e2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            age    weight     ap_hi     ap_lo  gender_1  gender_2  \\\n",
            "0     -0.436062 -0.847873 -0.122182 -0.088238       0.0       1.0   \n",
            "1      0.307686  0.749831  0.072610 -0.035180       1.0       0.0   \n",
            "2     -0.247997 -0.708942  0.007679 -0.141297       1.0       0.0   \n",
            "3     -0.748152  0.541435  0.137541  0.017879       0.0       1.0   \n",
            "4     -0.808543 -1.264666 -0.187113 -0.194356       1.0       0.0   \n",
            "...         ...       ...       ...       ...       ...       ...   \n",
            "69995 -0.092762  0.124642 -0.057251 -0.088238       0.0       1.0   \n",
            "69996  1.269492  3.597913  0.072610 -0.035180       1.0       0.0   \n",
            "69997 -0.163286  2.139139  0.332333 -0.035180       0.0       1.0   \n",
            "69998  1.200589 -0.153219  0.040145 -0.088238       1.0       0.0   \n",
            "69999  0.434144 -0.153219 -0.057251 -0.088238       1.0       0.0   \n",
            "\n",
            "       cholesterol_1  cholesterol_2  cholesterol_3  gluc_1  gluc_2  gluc_3  \\\n",
            "0                1.0            0.0            0.0     1.0     0.0     0.0   \n",
            "1                0.0            0.0            1.0     1.0     0.0     0.0   \n",
            "2                0.0            0.0            1.0     1.0     0.0     0.0   \n",
            "3                1.0            0.0            0.0     1.0     0.0     0.0   \n",
            "4                1.0            0.0            0.0     1.0     0.0     0.0   \n",
            "...              ...            ...            ...     ...     ...     ...   \n",
            "69995            1.0            0.0            0.0     1.0     0.0     0.0   \n",
            "69996            0.0            1.0            0.0     0.0     1.0     0.0   \n",
            "69997            0.0            0.0            1.0     1.0     0.0     0.0   \n",
            "69998            1.0            0.0            0.0     0.0     1.0     0.0   \n",
            "69999            0.0            1.0            0.0     1.0     0.0     0.0   \n",
            "\n",
            "       smoke_0  smoke_1  alco_0  alco_1  active_0  active_1  \n",
            "0          1.0      0.0     1.0     0.0       0.0       1.0  \n",
            "1          1.0      0.0     1.0     0.0       0.0       1.0  \n",
            "2          1.0      0.0     1.0     0.0       1.0       0.0  \n",
            "3          1.0      0.0     1.0     0.0       0.0       1.0  \n",
            "4          1.0      0.0     1.0     0.0       1.0       0.0  \n",
            "...        ...      ...     ...     ...       ...       ...  \n",
            "69995      0.0      1.0     1.0     0.0       0.0       1.0  \n",
            "69996      1.0      0.0     1.0     0.0       0.0       1.0  \n",
            "69997      1.0      0.0     0.0     1.0       1.0       0.0  \n",
            "69998      1.0      0.0     1.0     0.0       1.0       0.0  \n",
            "69999      1.0      0.0     1.0     0.0       0.0       1.0  \n",
            "\n",
            "[70000 rows x 18 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the data for training & testing\n",
        "train, test, target, target_test = train_test_split(data, data_target, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "kvlcturYg8oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curve(target, score):\n",
        "    fpr_log_reg, tpr_log_reg, thresholds = metrics.roc_curve(target, score)\n",
        "    plt.figure(1)\n",
        "    plt.plot(fpr_log_reg, tpr_log_reg, color='orange', lw=1)\n",
        "    plt.xlabel('FPR')\n",
        "    plt.ylabel('TPR')\n",
        "    plt.show()\n",
        "    # Print the area under ROC, which is also called \"AUC (Area Under the ROC curve)\"\n",
        "    aucroc = metrics.auc(fpr_log_reg, tpr_log_reg)\n",
        "    print('\\nAUC of ROC: ', aucroc)\n",
        "\n",
        "def print_four_metrics(target, predicted):\n",
        "    print(\"%-12s %f\" % ('Accuracy:', metrics.accuracy_score(target, predicted)))\n",
        "    print(\"%-12s %f\" % ('Precision:', metrics.precision_score(target, predicted, labels=None, pos_label=1, average='binary', sample_weight=None)))\n",
        "    print(\"%-12s %f\" % ('Recall:', metrics.recall_score(target, predicted, labels=None, pos_label=1, average='binary', sample_weight=None)))\n",
        "    print(\"%-12s %f\" % ('F1 Score:', metrics.f1_score(target, predicted, labels=None, pos_label=1, average='binary', sample_weight=None)))"
      ],
      "metadata": {
        "id": "2EDy8MRWhR1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "ltwu-NVwhcTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer_architecture = (25,25)\n",
        "mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_architecture,\n",
        "                    max_iter=100, alpha=1e-4,\n",
        "                    solver='sgd', verbose=True, tol=1e-4, random_state=1,\n",
        "                    activation='logistic',\n",
        "                    learning_rate_init=.1)\n",
        "mlp.fit(train, target)\n",
        "print('\\ntraining score: {}'.format(mlp.score(train, target)))\n",
        "print('test score: {}'.format(mlp.score(test, target_test)))\n",
        "#pred=mlp.predict_proba(test)[:,1]\n",
        "#print(pred)\n",
        "#pred=mlp.predict(test)\n",
        "#print(pred)\n",
        "#cut_off->0.5\n",
        "print_four_metrics(target_test, mlp.predict(test))\n",
        "plot_roc_curve(target_test, mlp.predict_proba(test)[:,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIB72yoGhdFc",
        "outputId": "612db265-3fbf-47b5-95ad-e70aae44b70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "training score: 0.7353392857142858\n",
            "test score: 0.7395\n",
            "[0.76642487 0.86378637 0.66515806 ... 0.46439762 0.57352061 0.8292063 ]\n",
            "[1 1 1 ... 0 1 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(25,):\n",
        "Accuracy:    0.737286\n",
        "Precision:   0.767834\n",
        "Recall:      0.681546\n",
        "F1 Score:    0.722121\n",
        "(25,25):\n",
        "Accuracy:    0.739500\n",
        "Precision:   0.770890\n",
        "Recall:      0.682829\n",
        "F1 Score:    0.724193\n",
        "(25,25,25,25):\n",
        "Accuracy:    0.737643\n",
        "Precision:   0.763953\n",
        "Recall:      0.689104\n",
        "F1 Score:    0.724601\n",
        "(5,5):\n",
        "Accuracy:    0.738143\n",
        "Precision:   0.757305\n",
        "Recall:      0.702225\n",
        "F1 Score:    0.728726\n",
        "(100,100):\n",
        "Accuracy:    0.736143\n",
        "Precision:   0.739809\n",
        "Recall:      0.729892\n",
        "F1 Score:    0.734817"
      ],
      "metadata": {
        "id": "C7vewKKz2zCQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}